{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting and generating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Generate 30 rows of synthetic data for tool calling where a user provides their user ID, and based on the user ID, the system retrieves all \n",
    "the orders the user has previously placed in the database. The generated data should include sample questions and corresponding answers,\n",
    "demonstrating the interaction between the user and the tool. Try to create as different scenarios as possible, Here are some examples:\n",
    "example1:\n",
    "query Perform a database query on the 'orders' table to retrieve orders placed in the last week. answers [{\"name\": \"simulate_query_database\", \"arguments\": {\"table\": \"orders\", \"conditions\": [{\"date\": {\"$gt\": \"2023-09-20\"}}]}}] tools [{\"name\": \"simulate_query_database\", \"description\": \"Simulates querying a database based on certain conditions.\", \"parameters\": {\"table\": {\"description\": \"Name of the table to query.\", \"type\": \"str\"}, \"conditions\": {\"description\": \"Conditions for the query, each condition is a dictionary.\", \"type\": \"list\"}}}, {\"name\": \"get_city_from_zipcode\", \"description\": \"Retrieves the city name for a given ZIP code using the Ziptastic API.\", \"parameters\": {\"zipcode\": {\"description\": \"The ZIP code to look up.\", \"type\": \"str\"}}}]\n",
    "example2:\n",
    "query Search for zip codes in Mexico related to the query 'Mexico City'. answers [{\"name\": \"search_zip_codes_in_mexico\", \"arguments\": {\"q\": \"Mexico City\"}}] tools [{\"name\": \"get_vector_tile\", \"description\": \"Fetches vector tiles based on the OpenMapTiles schema using the provided x, y, and z coordinates.\", \"parameters\": {\"x\": {\"description\": \"The X coordinate of the tile.\", \"type\": \"int\", \"default\": \"0\"}, \"y\": {\"description\": \"The Y coordinate of the tile.\", \"type\": \"int\", \"default\": \"0\"}, \"z\": {\"description\": \"The zoom level of the tile.\", \"type\": \"int\", \"default\": \"0\"}}}, {\"name\": \"geocode\", \"description\": \"Fetch geocoordinates for a given address using the TrueWay Geocoding API.\", \"parameters\": {\"address\": {\"description\": \"The address that you want to geocode.\", \"type\": \"str\", \"default\": \"505 Howard St, San Francisco\"}, \"language\": {\"description\": \"The language in which to return results. Default is 'en'.\", \"type\": \"str, optional\", \"default\": \"en\"}, \"country\": {\"description\": \"The country code to narrow the search results.\", \"type\": \"str, optional\", \"default\": \"\"}, \"bounds\": {\"description\": \"The bounding box to narrow the search results.\", \"type\": \"str, optional\", \"default\": \"\"}}}, {\"name\": \"reversegeocode\", \"description\": \"Obtain the human-readable address for a given geographical location.\", \"parameters\": {\"location\": {\"description\": \"The latitude and longitude coordinates (comma-separated) for which to obtain the address.\", \"type\": \"str\", \"default\": \"37.7879493,-122.3961974\"}, \"language\": {\"description\": \"The language in which to return results. Defaults to 'en'.\", \"type\": \"str, optional\", \"default\": \"en\"}}}, {\"name\": \"lookup_coordinates\", \"description\": \"Converts US latitude and longitude coordinates into local city information by querying the Reverse Geocode Locator API.\", \"parameters\": {\"lat\": {\"description\": \"The latitude coordinate.\", \"type\": \"int\", \"default\": \"40.785091\"}, \"long\": {\"description\": \"The longitude coordinate.\", \"type\": \"str\", \"default\": \"-73.968285\"}}}, {\"name\": \"local_osm_v1_z_x_y_png\", \"description\": \"Downloads an OpenStreetMap standard tile image for specified coordinates and zoom level.\", \"parameters\": {\"y\": {\"description\": \"y tile number.\", \"type\": \"int\", \"default\": \"3\"}, \"z\": {\"description\": \"Zoom factor between 0 and 19.\", \"type\": \"int\", \"default\": \"3\"}, \"x\": {\"description\": \"x tile number.\", \"type\": \"int\", \"default\": \"6\"}}}, {\"name\": \"search_zip_codes_in_mexico\", \"description\": \"Performs a text search for zip codes in Mexico using the provided query string.\", \"parameters\": {\"q\": {\"description\": \"The search query string to look up zip codes.\", \"type\": \"str\", \"default\": \"cerrada san mibuel\"}}}]\n",
    "example3:\n",
    "query Simulate a database query for the 'Users' table with conditions {'age': 30, 'city': 'Berlin'} and determine if 2024 is a leap year. answers [{\"name\": \"simulate_query_database\", \"arguments\": {\"table\": \"Users\", \"conditions\": [{\"age\": 30, \"city\": \"Berlin\"}]}}, {\"name\": \"is_leap_year\", \"arguments\": {\"year\": 2024}}] tools [{\"name\": \"is_leap_year\", \"description\": \"Checks if a year is a leap year.\", \"parameters\": {\"year\": {\"description\": \"The year to check.\", \"type\": \"int\"}}}, {\"name\": \"is_hotel_available\", \"description\": \"Checks the availability of a hotel for a given date range.\", \"parameters\": {\"hotel\": {\"description\": \"The name of the hotel.\", \"type\": \"str\"}, \"city\": {\"description\": \"The city where the hotel is located.\", \"type\": \"str\"}, \"checkin\": {\"description\": \"The check-in date in the format \\\"YYYY-MM-DD\\\".\", \"type\": \"str\"}, \"checkout\": {\"description\": \"The check-out date in the format \\\"YYYY-MM-DD\\\".\", \"type\": \"str\"}}}, {\"name\": \"simulate_query_database\", \"description\": \"Simulates querying a database based on certain conditions.\", \"parameters\": {\"table\": {\"description\": \"Name of the table to query.\", \"type\": \"str\"}, \"conditions\": {\"description\": \"Conditions for the query, each condition is a dictionary.\", \"type\": \"list\"}}}] \n",
    "Use these examples as a reference to generate synthetic data for tool calling, \n",
    "focusing on how users provide their user ID and the system retrieves their order history from the database.'''\n",
    "\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"api_key\",\n",
    "    base_url=\"https://api.aimlapi.com\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant who creates synthetic data for tool calling. \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=16000,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "message = response.choices[0].message.content\n",
    "\n",
    "#print(f\"Assistant: {message}\")\n",
    "messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(text):\n",
    "    sections = re.split(r'Row \\d+\\s*', text)\n",
    "    return sections[1:]\n",
    "\n",
    "#message = split_string(message)\n",
    "messages = [split_string(i) for i in messages]\n",
    "\n",
    "que = []\n",
    "ans = []\n",
    "tool = []\n",
    "for i in messages:\n",
    "    try:\n",
    "        data = i.strip()\n",
    "        Tools = data.split('Tools:')[1].strip()\n",
    "        Answer = data.split('Answer:')[1].split('Tools:')[0].strip()\n",
    "        Question = data.split('Answer:')[1].strip()\n",
    "        que.append(Question)\n",
    "        ans.append(Answer)\n",
    "        tool.append(Tools)\n",
    "    except:\n",
    "        que.append(np.nan)\n",
    "        ans.append(np.nan)\n",
    "        tool.append(np.nan)\n",
    "\n",
    "df_syn_2 = pd.DataFrame({'query': que, 'answers': ans, 'tools': tool})\n",
    "df_final = pd.DataFrame(df_syn_2).dropna()\n",
    "data_tt_df = df_final.reset_index()\n",
    "data_tt_df.drop('level_0', axis=1, inplace=True)\n",
    "# synthetic_data = pd.concat([df_final, data_tt_df], axis=0)\n",
    "# synthetic_data.to_csv('final_fintune_data.csv')\n",
    "data_tt_df.to_csv('final_fintune_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated data and xlam data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch \n",
    "import random\n",
    "\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE_DIR\"] = \"huggingface_hub_cache\"\n",
    "df = pd.read_csv('final_fintune_data.csv')\n",
    "\n",
    "data_tt = [] \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "for _, i in df.iterrows():\n",
    "    if i['query'].lower().__contains__('query'):\n",
    "        data_tt.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "data_tt_df = pd.DataFrame(data_tt)\n",
    "data_tt_df.columns = ['index', 'query', 'answers', 'tools']\n",
    "\n",
    "count = 0\n",
    "for _, i in data_tt_df.iterrows():\n",
    "    if i['query'].lower().__contains__('query'):\n",
    "        print('query {} \\n'.format(i['query']).strip(), 'answers {} \\n'.format(i['answers']).strip() , 'tools {}'.format(i['tools']).strip())\n",
    "        count +=1\n",
    "        if count == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to finetune XLAM with llama3.1 generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import multiprocessing\n",
    "import json\n",
    "import torch \n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "import ast\n",
    "import random\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "!export HF_TOKEN='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'\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE_DIR\"] = \"huggingface_hub_cache\"\n",
    "model_name = \"Salesforce/xLAM-1b-fc-r\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "\n",
    "df = pd.read_csv('final_fintune_data.csv')\n",
    "df = df[['index', 'query', 'answers', 'tools']]\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "def process(row):\n",
    "    row[\"query\"] = \"<user>\"+row[\"query\"]+\"</user>\\n\\n\"\n",
    "    tools = []\n",
    "    for t in json.loads(row[\"tools\"]):\n",
    "      tools.append(str(t))\n",
    "    answers = []\n",
    "    for a in json.loads(row[\"answers\"]):\n",
    "      answers.append(str(a))\n",
    "    row[\"tools\"] = \"<tools>\"+\"\\n\".join(tools)+\"</tools>\\n\\n\"\n",
    "    row[\"answers\"] = \"<calls>\"+\"\\n\".join(answers)+\"</calls>\"\n",
    "    row[\"text\"] = row[\"query\"]+row[\"tools\"]+row[\"answers\"]+tokenizer.eos_token\n",
    "    return row\n",
    "ds = ds.map(\n",
    "    process,\n",
    "    num_proc= multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_bf16_supported():\n",
    "  os.system('pip install flash_attn')\n",
    "  compute_dtype = torch.bfloat16\n",
    "  attn_implementation = 'flash_attention_2'\n",
    "else:\n",
    "  compute_dtype = torch.float16\n",
    "  attn_implementation = 'sdpa'\n",
    "\n",
    "def QLoRA(ds):\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(load_in_8bit=True, bnb_8bit_quant_type=\"nf4\", bnb_8bit_compute_dtype=compute_dtype, bnb_8bit_use_double_quant=True,)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, quantization_config=bnb_config, device_map={\"\": 0}, attn_implementation=attn_implementation\n",
    "  )\n",
    "    model = prepare_model_for_kbit_training(model, gradient_checkpointing_kwargs={'use_reentrant':True})\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.use_cache = False \n",
    "    peft_config = LoraConfig(\n",
    "          lora_alpha=16,\n",
    "          lora_dropout=0.05,\n",
    "          r=64,\n",
    "          bias=\"none\",\n",
    "          task_type=\"CAUSAL_LM\",\n",
    "          target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    "    )\n",
    "    training_arguments = SFTConfig(\n",
    "          output_dir=\"./xLAM\",\n",
    "          optim=\"adamw_8bit\",\n",
    "          per_device_train_batch_size=2,\n",
    "          gradient_accumulation_steps=1,\n",
    "          log_level=\"debug\",\n",
    "          save_steps=500,\n",
    "          logging_steps=10,\n",
    "          learning_rate=1e-4,\n",
    "          fp16 = not torch.cuda.is_bf16_supported(),\n",
    "          bf16 = torch.cuda.is_bf16_supported(),\n",
    "          max_steps=1000,\n",
    "          warmup_ratio=0.1,\n",
    "          lr_scheduler_type=\"linear\",\n",
    "          dataset_text_field=\"text\",\n",
    "          max_seq_length=512,\n",
    "    )\n",
    "    trainer = SFTTrainer(\n",
    "          model=model,\n",
    "          train_dataset=ds,\n",
    "          peft_config=peft_config,\n",
    "          tokenizer=tokenizer,\n",
    "          args=training_arguments,\n",
    "    )\n",
    "    with torch.cuda.amp.autocast():\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting some customer data into DB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (THIS IS DUMMY DATA JUST PRESENTED TO CHECK CHATBOT PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import random\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def connection_to_db():\n",
    "    username = 'postgres'\n",
    "    password = '1234'\n",
    "    host = 'localhost'\n",
    "    port = '5432'\n",
    "    dbname = 'postgres'\n",
    "\n",
    "    engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{dbname}')\n",
    "    conn = engine.connect()\n",
    "    return conn\n",
    "\n",
    "df_db = pd.read_csv('customers_shopping_data_db.csv')\n",
    "df_db.drop('customer_id', axis=1, inplace=True)\n",
    "df_db['customer_id'] = ['C'+str(random.randint(1001, 4000)) for _ in range(len(df_db))]\n",
    "df_db = df_db[['invoice_no', 'items', 'quantity', 'price', 'customer_id', 'order_date']]\n",
    "\n",
    "df_db['order_date'] = pd.to_datetime(df_db['order_date'], format='%d.%m.%Y')\n",
    "\n",
    "conn = connection_to_db()\n",
    "\n",
    "dtype = {\n",
    "    'invoice_no': sqlalchemy.types.String,\n",
    "    'items': sqlalchemy.types.String,\n",
    "    'quantity': sqlalchemy.types.Integer,\n",
    "    'price': sqlalchemy.types.Float,\n",
    "    'customer_id': sqlalchemy.types.String,\n",
    "    'order_date': sqlalchemy.types.DateTime\n",
    "}\n",
    "\n",
    "df_db.to_sql(\"customers_shopping_data\", conn, if_exists=\"replace\", index=False, dtype=dtype)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "from peft import PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import json\n",
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import ast\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import pandas as  pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlalchemy\n",
    "import random\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def connection_to_db():\n",
    "    username = 'postgres'\n",
    "    password = '1234'\n",
    "    host = 'localhost'\n",
    "    port = '5432'\n",
    "    dbname = 'postgres'\n",
    "\n",
    "    engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{dbname}')\n",
    "    conn = engine.connect() \n",
    "    return conn\n",
    "\n",
    "torch.random.manual_seed(0) \n",
    "\n",
    "compute_dtype = torch.float16\n",
    "attn_implementation = 'sdpa'\n",
    "quantization_config=BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=compute_dtype,\n",
    "    bnb_8bit_use_double_quant=True,\n",
    "    bnb_8bit_quant_type=\"nf8\",\n",
    ")\n",
    "adapter= \"./checkpoint-1000\"\n",
    "model_name = \"Salesforce/xLAM-1b-fc-r\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "print(f\"Starting to load the model {model_name} into memory\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=attn_implementation,\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question(query, model, tokenizer):\n",
    "\n",
    "    task_instruction = \"\"\"\n",
    "    You are an expert in composing functions. You are given a question and a set of possible functions. \n",
    "    Based on the question, you will need to make one or more function/tool calls to achieve the purpose. \n",
    "    If none of the functions can be used, point it out and refuse to answer. \n",
    "    If the given question lacks the parameters required by the function, also point it out.\n",
    "    \"\"\".strip()\n",
    "\n",
    "    format_instruction = \"\"\"\n",
    "    The output MUST strictly adhere to the following JSON format, and NO other text MUST be included.\n",
    "    The example format is as follows. Please make sure the parameter type is correct. If no function call is needed, please make tool_calls an empty list '[]'.\n",
    "    ```\n",
    "    {\n",
    "        \"tool_calls\": [\n",
    "        {\"name\": \"func_name1\", \"arguments\": {\"argument1\": \"value1\", \"argument2\": \"value2\"}},\n",
    "        ... (more tool calls as required)\n",
    "        ]\n",
    "    }\n",
    "    ```\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "    get_customer_orders_api = {\n",
    "    \"name\": \"get_customer_orders\",\n",
    "    \"description\": \"Retrieve 'N' prior orders for a customer using their customer ID\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"customer_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unique identifier for the customer\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"limit\"]\n",
    "    }\n",
    "}\n",
    "    \n",
    "    suggest_orders_api = {\n",
    "        \"name\": \"suggest_orders\",\n",
    "        \"description\": \"Suggest additional orders based on a customer's previous purchases, USE ONLY WHEN CUSTOMERS ARE REQUESTING FOR RECOMMENDATIONS IN THE QUESTION\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"customer_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier for the customer\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    get_order_details_api = {\n",
    "        \"name\": \"get_order_details\",\n",
    "        \"description\": \"Retrieve details of a specific order using the invoice number, USE ONLY WHEN INVOICE IS MENTIONED IN THE QUESTION\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"invoice_no\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The invoice number of the order\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"invoice_no\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    get_order_history_by_items_api = {\n",
    "        \"name\": \"get_order_history_by_items\",\n",
    "        \"description\": \"Retrieve all orders of a specific items for a customer, USE ONLY WHEN ITEMS IS MENTIONED IN THE QUESTION\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"customer_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier for the customer\"\n",
    "                },\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The particular item purchased by the customer\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"items\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    get_frequent_purchases_api = {\n",
    "        \"name\": \"get_frequent_purchases\",\n",
    "        \"description\": \"Get frequently purchased items by a customer\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"customer_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier for the customer\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    calculate_total_spend_api = {\n",
    "        \"name\": \"calculate_total_spend\",\n",
    "        \"description\": \"Calculate the total amount spent by a customer.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"customer_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier for the customer\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    get_customer_profile_api = {\n",
    "        \"name\": \"get_customer_profile\",\n",
    "        \"description\": \"Retrieve the profile information of a customer\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"customer_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique identifier for the customer\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    openai_format_tools = [get_customer_orders_api , suggest_orders_api, get_order_details_api, get_order_history_by_items_api, \n",
    "                           get_frequent_purchases_api, calculate_total_spend_api, get_customer_profile_api]\n",
    "\n",
    "    def convert_to_xlam_tool(tools):\n",
    "        ''''''\n",
    "        if isinstance(tools, dict):\n",
    "            return {\n",
    "                \"name\": tools[\"name\"],\n",
    "                \"description\": tools[\"description\"],\n",
    "                \"parameters\": {k: v for k, v in tools[\"parameters\"].get(\"properties\", {}).items()}\n",
    "            }\n",
    "        elif isinstance(tools, list):\n",
    "            return [convert_to_xlam_tool(tool) for tool in tools]\n",
    "        else:\n",
    "            return tools\n",
    "\n",
    "    def build_prompt(task_instruction: str, format_instruction: str, tools: list, query: str):\n",
    "        prompt = f\"[BEGIN OF TASK INSTRUCTION]\\n{task_instruction}\\n[END OF TASK INSTRUCTION]\\n\\n\"\n",
    "        prompt += f\"[BEGIN OF AVAILABLE TOOLS]\\n{json.dumps(xlam_format_tools)}\\n[END OF AVAILABLE TOOLS]\\n\\n\"\n",
    "        prompt += f\"[BEGIN OF FORMAT INSTRUCTION]\\n{format_instruction}\\n[END OF FORMAT INSTRUCTION]\\n\\n\"\n",
    "        prompt += f\"[BEGIN OF QUERY]\\n{query}\\n[END OF QUERY]\\n\\n\"\n",
    "        return prompt\n",
    "        \n",
    "    # Build the input and start the inference\n",
    "    xlam_format_tools = convert_to_xlam_tool(openai_format_tools)\n",
    "    content = build_prompt(task_instruction, format_instruction, xlam_format_tools, query)\n",
    "\n",
    "    messages=[\n",
    "        { 'role': 'user', 'content': content}\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # tokenizer.eos_token_id is the id of <|EOT|> token\n",
    "    outputs = model.generate(inputs, max_new_tokens=512, temperature=1, do_sample=True, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_orders_def(customer_id='C3628', limit=5, **kwargs):\n",
    "    data =  []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT * FROM customers_shopping_data WHERE customer_id = '{customer_id}' ORDER BY order_date DESC LIMIT '{limit}'\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def suggest_orders_def(customer_id='C3628', limit=5, similarity_threshold=0.8, **kwargs):\n",
    "    conn = connection_to_db()\n",
    "    query = \"\"\"\n",
    "    SELECT customer_id, items, SUM(quantity) as total_quantity\n",
    "    FROM customers_shopping_data\n",
    "    GROUP BY customer_id, items\n",
    "    \"\"\"\n",
    "    \n",
    "    purchase_history = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    user_item_matrix = purchase_history.pivot(index='customer_id', columns='items', values='total_quantity').fillna(0)\n",
    "\n",
    "    if customer_id not in user_item_matrix.index:\n",
    "        return []\n",
    "\n",
    "    model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    model.fit(user_item_matrix)\n",
    "\n",
    "    customer_idx = user_item_matrix.index.get_loc(customer_id)\n",
    "    distances, indices = model.kneighbors(user_item_matrix.iloc[customer_idx, :].values.reshape(1, -1), n_neighbors=len(user_item_matrix))\n",
    "\n",
    "    similar_customers = [user_item_matrix.index[i] for i, dist in zip(indices.flatten(), distances.flatten()) if dist <= 1 - similarity_threshold and user_item_matrix.index[i] != customer_id]\n",
    "\n",
    "    if len(similar_customers) < 10:\n",
    "        similar_customers = user_item_matrix.index[indices.flatten()[1:11]]\n",
    "\n",
    "    similar_customers_purchases = user_item_matrix.loc[similar_customers].sum(axis=0).sort_values(ascending=False)\n",
    "    \n",
    "    target_customer_purchases = user_item_matrix.loc[customer_id]\n",
    "    target_categories = target_customer_purchases[target_customer_purchases > 0].index\n",
    "    recommended_products = similar_customers_purchases[~similar_customers_purchases.index.isin(target_categories)]\n",
    "    \n",
    "    return recommended_products.head(limit).index.tolist()\n",
    "\n",
    "def get_order_details_def(invoice_no, **kwargs):\n",
    "    data =  []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT * FROM customers_shopping_data WHERE invoice_no = '{invoice_no}'\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_order_history_by_items_def(customer_id='C3628', **kwargs):\n",
    "    data =  []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT items, SUM(quantity) as total_quantity FROM customers_shopping_data WHERE customer_id = '{customer_id}' GROUP BY items ORDER BY total_quantity DESC\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_frequent_purchases_def(customer_id='C3628', **kwargs):\n",
    "    data =  []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT items, SUM(quantity) as total_quantity FROM customers_shopping_data WHERE customer_id = '{customer_id}' GROUP BY items ORDER BY total_quantity DESC\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def calculate_total_spend_def(customer_id='C3628', **kwargs):\n",
    "    data = []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT SUM(price) FROM customers_shopping_data WHERE customer_id = '{customer_id}'\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_top_categories_def(customer_id='C3628', **kwargs):\n",
    "    data =  []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT items, SUM(quantity) as total_quantity FROM customers_shopping_data WHERE customer_id = '{customer_id}' GROUP BY items ORDER BY total_quantity DESC LIMIT 5\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_customer_profile_def(customer_id='C3628', **kwargs):\n",
    "    data =  []\n",
    "    conn = connection_to_db()\n",
    "    query = f\"SELECT * FROM customers_shopping_data WHERE customer_id = '{customer_id}'\"\n",
    "    result = conn.execute(text(query))\n",
    "    conn.close()\n",
    "    for row in result:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "functions_list = {\n",
    "    \"get_customer_orders\": get_customer_orders_def,\n",
    "    \"suggest_orders\": suggest_orders_def,\n",
    "    \"get_order_details\": get_order_details_def,\n",
    "    \"get_order_history_by_items\": get_order_history_by_items_def,\n",
    "    \"get_frequent_purchases\": get_frequent_purchases_def,\n",
    "    \"calculate_total_spend\": calculate_total_spend_def,\n",
    "    \"get_top_categories\": get_top_categories_def,\n",
    "    \"get_customer_profile\": get_customer_profile_def\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = 'C2214'\n",
    "query = f\"for customer_id: {customer_id} give me last 7 orders and also recommend me some products for customer_id:{customer_id}\"\n",
    "out = question(query, model, tokenizer)\n",
    "output_cleaned = ast.literal_eval(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in output_cleaned['tool_calls']:\n",
    "    print(functions_list[tool['name']](**tool['arguments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4620432,
     "sourceId": 7873901,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
